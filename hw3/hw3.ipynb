{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 21:04:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-vt2182:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9a8371cca0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "conf.set('spark.ui.proxyBase', '/user/' + os.environ['JUPYTERHUB_USER'] + '/proxy/4040')\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datafile: BreadBasket_DMS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read\\\n",
    "    .option('delimiter',',')\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"shared/hw2/BreadBasket_DMS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Transaction: integer (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.datetime(2016, 10, 30, 0, 0), Time=datetime.datetime(2023, 3, 12, 9, 58, 11), Transaction=1, Item='Bread')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------+-------------+\n",
      "|               Date|               Time|Transaction|         Item|\n",
      "+-------------------+-------------------+-----------+-------------+\n",
      "|2016-10-30 00:00:00|2023-03-12 09:58:11|          1|        Bread|\n",
      "|2016-10-30 00:00:00|2023-03-12 10:05:34|          2| Scandinavian|\n",
      "|2016-10-30 00:00:00|2023-03-12 10:05:34|          2| Scandinavian|\n",
      "|2016-10-30 00:00:00|2023-03-12 10:07:57|          3|Hot chocolate|\n",
      "|2016-10-30 00:00:00|2023-03-12 10:07:57|          3|          Jam|\n",
      "+-------------------+-------------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most popular (most sold) between the 8:00AM and 8:59AM for each day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Count: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-----+\n",
      "|               Date|   Item|Count|\n",
      "+-------------------+-------+-----+\n",
      "|2016-11-05 00:00:00|   NONE|    1|\n",
      "|2017-03-09 00:00:00| Coffee|    2|\n",
      "|2017-04-04 00:00:00|Cookies|    1|\n",
      "|2017-04-06 00:00:00| Coffee|    2|\n",
      "|2017-01-28 00:00:00|Brownie|    1|\n",
      "+-------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour\n",
    "\n",
    "df_grouped = df.filter((hour(\"Time\") == 8))\\\n",
    "    .groupBy(\"Date\", \"Item\")\\\n",
    "    .agg({\"Transaction\": \"count\"})\\\n",
    "    .withColumnRenamed(\"count(Transaction)\", \"Count\")\n",
    "\n",
    "df_grouped.printSchema()\n",
    "df_grouped.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- MaxCount: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|               Date|MaxCount|\n",
      "+-------------------+--------+\n",
      "|2016-11-18 00:00:00|       6|\n",
      "|2016-11-02 00:00:00|       8|\n",
      "|2017-03-30 00:00:00|       3|\n",
      "|2017-04-08 00:00:00|       4|\n",
      "|2016-12-01 00:00:00|       1|\n",
      "+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "df_max_count = df_grouped.groupBy(\"Date\")\\\n",
    "    .agg(max(\"Count\").alias(\"MaxCount\"))\n",
    "\n",
    "df_max_count.printSchema()\n",
    "df_max_count.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      "\n",
      "+-------------------+----------------+\n",
      "|               Date|            Item|\n",
      "+-------------------+----------------+\n",
      "|2016-11-18 00:00:00|          Coffee|\n",
      "|2016-11-02 00:00:00|          Coffee|\n",
      "|2017-03-30 00:00:00|Christmas common|\n",
      "|2017-03-30 00:00:00|          Coffee|\n",
      "|2017-04-08 00:00:00|           Bread|\n",
      "+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = df_grouped.join(df_max_count, \"Date\")\\\n",
    "    .filter(df_grouped.Count == df_max_count.MaxCount)\\\n",
    "    .drop('Count', 'MaxCount')\\\n",
    "\n",
    "df_result.printSchema()\n",
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|               Date|     Item|\n",
      "+-------------------+---------+\n",
      "|2016-10-31 00:00:00|    Bread|\n",
      "|2016-10-31 00:00:00|   Coffee|\n",
      "|2016-11-01 00:00:00|      Tea|\n",
      "|2016-11-02 00:00:00|   Coffee|\n",
      "|2016-11-03 00:00:00|   Coffee|\n",
      "|2016-11-04 00:00:00|    Bread|\n",
      "|2016-11-04 00:00:00|   Coffee|\n",
      "|2016-11-05 00:00:00|    Bread|\n",
      "|2016-11-07 00:00:00|   Coffee|\n",
      "|2016-11-07 00:00:00|   Pastry|\n",
      "|2016-11-08 00:00:00|   Coffee|\n",
      "|2016-11-08 00:00:00|    Bread|\n",
      "|2016-11-08 00:00:00|   Pastry|\n",
      "|2016-11-09 00:00:00|   Coffee|\n",
      "|2016-11-09 00:00:00|   Pastry|\n",
      "|2016-11-09 00:00:00|    Bread|\n",
      "|2016-11-10 00:00:00|   Coffee|\n",
      "|2016-11-11 00:00:00|    Bread|\n",
      "|2016-11-12 00:00:00|   Coffee|\n",
      "|2016-11-12 00:00:00|Medialuna|\n",
      "+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.sort('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What is the most common item bought along with “Brownie”? (items bought in the same transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Transaction: integer (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n",
      "+-----------+-----+\n",
      "|Transaction|count|\n",
      "+-----------+-----+\n",
      "|       1238|    1|\n",
      "|       3749|    1|\n",
      "|       7554|    1|\n",
      "|       8389|    1|\n",
      "|        392|    1|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "df_grouped = df.filter(df.Item == \"Brownie\")\\\n",
    "    .groupBy(\"Transaction\")\\\n",
    "    .count()\n",
    "\n",
    "df_grouped.printSchema()\n",
    "df_grouped.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Count: long (nullable = false)\n",
      "\n",
      "+-----------------+-----+\n",
      "|             Item|Count|\n",
      "+-----------------+-----+\n",
      "|           Muffin|   18|\n",
      "|            Salad|    1|\n",
      "|    Bowl Nic Pitt|    1|\n",
      "|        Alfajores|   27|\n",
      "|Hearty & Seasonal|    6|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_counted = df_grouped.join(df, \"Transaction\")\\\n",
    "    .groupBy(\"Item\")\\\n",
    "    .agg(count(\"Transaction\").alias(\"Count\"))\n",
    "\n",
    "df_counted.printSchema()\n",
    "df_counted.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Item|Count|\n",
      "+-------+-----+\n",
      "|Brownie|  379|\n",
      "| Coffee|  237|\n",
      "|  Bread|  115|\n",
      "|    Tea|   71|\n",
      "|   Cake|   43|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df_counted.sort(desc('Count')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coffee'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counted.filter(df_counted.Item != \"Brownie\")\\\n",
    "    .orderBy(df_counted.Count.desc())\\\n",
    "    .first()[\"Item\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Restaurants_in_Durham_County_NC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option('delimiter',';')\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"shared/hw2/Restaurants_in_Durham_County_NC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Premise_Name: string (nullable = true)\n",
      " |-- Premise_Address1: string (nullable = true)\n",
      " |-- Premise_Address2: string (nullable = true)\n",
      " |-- Premise_City: string (nullable = true)\n",
      " |-- Premise_State: string (nullable = true)\n",
      " |-- Premise_Zip: string (nullable = true)\n",
      " |-- Premise_Phone: string (nullable = true)\n",
      " |-- Hours_Of_Operation: string (nullable = true)\n",
      " |-- Opening_Date: string (nullable = true)\n",
      " |-- Closing_Date: string (nullable = true)\n",
      " |-- Seats: string (nullable = true)\n",
      " |-- Water: string (nullable = true)\n",
      " |-- Sewage: string (nullable = true)\n",
      " |-- Insp_Freq: string (nullable = true)\n",
      " |-- Est_Group_Desc: string (nullable = true)\n",
      " |-- Risk: integer (nullable = true)\n",
      " |-- Smoking_Allowed: string (nullable = true)\n",
      " |-- Type_Description: string (nullable = true)\n",
      " |-- Rpt_Area_Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Transitional_Type_Desc: string (nullable = true)\n",
      " |-- geolocation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID='56060', Premise_Name='WEST 94TH ST PUB', Premise_Address1='4711 HOPE VALLEY RD', Premise_Address2='SUITE 6C', Premise_City='DURHAM', Premise_State='NC', Premise_Zip='27707', Premise_Phone='(919) 403-0025', Hours_Of_Operation=None, Opening_Date='1994-09-01', Closing_Date=None, Seats='60', Water='5 - Municipal/Community', Sewage='3 - Municipal/Community', Insp_Freq='4', Est_Group_Desc='Full-Service Restaurant', Risk=4, Smoking_Allowed='NO', Type_Description='1 - Restaurant', Rpt_Area_Desc='Food Service', Status='ACTIVE', Transitional_Type_Desc='FOOD', geolocation='35.9207272, -78.9573299')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "|   ID|        Premise_Name|    Premise_Address1|Premise_Address2|Premise_City|Premise_State|Premise_Zip| Premise_Phone|Hours_Of_Operation|Opening_Date|Closing_Date|Seats|               Water|              Sewage|Insp_Freq|      Est_Group_Desc|Risk|Smoking_Allowed|    Type_Description|   Rpt_Area_Desc|Status|Transitional_Type_Desc|         geolocation|\n",
      "+-----+--------------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "|56060|    WEST 94TH ST PUB| 4711 HOPE VALLEY RD|        SUITE 6C|      DURHAM|           NC|      27707|(919) 403-0025|              null|  1994-09-01|        null|   60|5 - Municipal/Com...|3 - Municipal/Com...|        4|Full-Service Rest...|   4|             NO|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|35.9207272, -78.9...|\n",
      "|58123|BROOKDALE DURHAM IFS|4434 BEN FRANKLIN...|            null|      DURHAM|           NC|      27704|(919) 479-9966|              null|  2003-10-15|        null|  350|5 - Municipal/Com...|3 - Municipal/Com...|        4|        Nursing Home|   4|             NO|16 - Institutiona...|    Food Service|ACTIVE|                  FOOD|36.0467802, -78.8...|\n",
      "|70266|       SMOOTHIE KING|1125 W. NC HWY 54...|            null|      DURHAM|           NC|      27707|(919) 489-7300|              null|  2009-07-09|        null|    7|5 - Municipal/Com...|3 - Municipal/Com...|        2|Fast Food Restaurant|   2|             NO|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|35.9182655, -78.9...|\n",
      "|97837|HAMPTON INN & SUITES|   1542 N GREGSON ST|            null|      DURHAM|           NC|      27701|(919) 688-8880|              null|  2012-01-09|        null|  100|5 - Municipal/Com...|3 - Municipal/Com...|        2|Full-Service Rest...|   2|             NO|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|36.0183378, -78.9...|\n",
      "|60690|BETTER LIVING CON...|       909 GARCIA ST|            null|      DURHAM|           NC|      27704|(919) 477-5825|              null|  2008-06-02|        null|    6|5 - Municipal/Com...|3 - Municipal/Com...|        1|                null|   0|            N/A|43 - Residential ...|Residential Care|ACTIVE|                   N/A|36.0556347, -78.9...|\n",
      "+-----+--------------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "How many years are represented in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Premise_Name: string (nullable = true)\n",
      " |-- Premise_Address1: string (nullable = true)\n",
      " |-- Premise_Address2: string (nullable = true)\n",
      " |-- Premise_City: string (nullable = true)\n",
      " |-- Premise_State: string (nullable = true)\n",
      " |-- Premise_Zip: string (nullable = true)\n",
      " |-- Premise_Phone: string (nullable = true)\n",
      " |-- Hours_Of_Operation: string (nullable = true)\n",
      " |-- Opening_Date: string (nullable = true)\n",
      " |-- Closing_Date: date (nullable = true)\n",
      " |-- Seats: string (nullable = true)\n",
      " |-- Water: string (nullable = true)\n",
      " |-- Sewage: string (nullable = true)\n",
      " |-- Insp_Freq: string (nullable = true)\n",
      " |-- Est_Group_Desc: string (nullable = true)\n",
      " |-- Risk: integer (nullable = true)\n",
      " |-- Smoking_Allowed: string (nullable = true)\n",
      " |-- Type_Description: string (nullable = true)\n",
      " |-- Rpt_Area_Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Transitional_Type_Desc: string (nullable = true)\n",
      " |-- geolocation: string (nullable = true)\n",
      "\n",
      "+-----+--------------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "|   ID|        Premise_Name|    Premise_Address1|Premise_Address2|Premise_City|Premise_State|Premise_Zip| Premise_Phone|Hours_Of_Operation|Opening_Date|Closing_Date|Seats|               Water|              Sewage|Insp_Freq|      Est_Group_Desc|Risk|Smoking_Allowed|    Type_Description|   Rpt_Area_Desc|Status|Transitional_Type_Desc|         geolocation|\n",
      "+-----+--------------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "|56060|    WEST 94TH ST PUB| 4711 HOPE VALLEY RD|        SUITE 6C|      DURHAM|           NC|      27707|(919) 403-0025|              null|  1994-09-01|        null|   60|5 - Municipal/Com...|3 - Municipal/Com...|        4|Full-Service Rest...|   4|             NO|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|35.9207272, -78.9...|\n",
      "|58123|BROOKDALE DURHAM IFS|4434 BEN FRANKLIN...|            null|      DURHAM|           NC|      27704|(919) 479-9966|              null|  2003-10-15|        null|  350|5 - Municipal/Com...|3 - Municipal/Com...|        4|        Nursing Home|   4|             NO|16 - Institutiona...|    Food Service|ACTIVE|                  FOOD|36.0467802, -78.8...|\n",
      "|70266|       SMOOTHIE KING|1125 W. NC HWY 54...|            null|      DURHAM|           NC|      27707|(919) 489-7300|              null|  2009-07-09|        null|    7|5 - Municipal/Com...|3 - Municipal/Com...|        2|Fast Food Restaurant|   2|             NO|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|35.9182655, -78.9...|\n",
      "|97837|HAMPTON INN & SUITES|   1542 N GREGSON ST|            null|      DURHAM|           NC|      27701|(919) 688-8880|              null|  2012-01-09|        null|  100|5 - Municipal/Com...|3 - Municipal/Com...|        2|Full-Service Rest...|   2|             NO|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|36.0183378, -78.9...|\n",
      "|60690|BETTER LIVING CON...|       909 GARCIA ST|            null|      DURHAM|           NC|      27704|(919) 477-5825|              null|  2008-06-02|        null|    6|5 - Municipal/Com...|3 - Municipal/Com...|        1|                null|   0|            N/A|43 - Residential ...|Residential Care|ACTIVE|                   N/A|36.0556347, -78.9...|\n",
      "+-----+--------------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, year\n",
    "\n",
    "df_clean = df.withColumn('Opening_Date', to_date('Opening_Date'))\n",
    "df_clean = df.withColumn('Closing_Date', to_date('Closing_Date', 'dd-MMM-yyyy'))\n",
    "\n",
    "df_clean.printSchema()\n",
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1990,\n",
       " 1991,\n",
       " 1992,\n",
       " 1993,\n",
       " 1994,\n",
       " 1995,\n",
       " 1996,\n",
       " 1997,\n",
       " 1998,\n",
       " 1999,\n",
       " 2000,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2012,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = []\n",
    "\n",
    "years.extend(df.select(year('Opening_Date').alias('year')).rdd.flatMap(lambda x: x).collect())\n",
    "years.extend(df.select(year('Closing_Date').alias('year')).rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "years = [i for i in years if i is not None]\n",
    "years = list(set(years))\n",
    "\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(years[-1] - years[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Show the type and count of restaurant opened during the 90’s (1990-1999 inclusive). Note: type=`Rpt_Area_Desc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|     Rpt_Area_Desc|count|\n",
      "+------------------+-----+\n",
      "|Bed&Breakfast Home|    3|\n",
      "|      Summer Camps|    1|\n",
      "|      Institutions|   16|\n",
      "| Local Confinement|    2|\n",
      "|  School Buildings|   56|\n",
      "|    Swimming Pools|  256|\n",
      "|          Day Care|   58|\n",
      "| Bed&Breakfast Inn|    1|\n",
      "|           Lodging|   21|\n",
      "|      Food Service|  204|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, count\n",
    "\n",
    "df.filter(\n",
    "    (year(\"Opening_Date\") >= 1990) & (year(\"Opening_Date\") <= 1999)\n",
    ")\\\n",
    "    .groupBy(\"Rpt_Area_Desc\")\\\n",
    "    .count()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: populationbycountry19802010millions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option('delimiter',',')\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"shared/hw2/populationbycountry19802010millions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- 1980: string (nullable = true)\n",
      " |-- 1981: string (nullable = true)\n",
      " |-- 1982: string (nullable = true)\n",
      " |-- 1983: string (nullable = true)\n",
      " |-- 1984: string (nullable = true)\n",
      " |-- 1985: string (nullable = true)\n",
      " |-- 1986: string (nullable = true)\n",
      " |-- 1987: string (nullable = true)\n",
      " |-- 1988: string (nullable = true)\n",
      " |-- 1989: string (nullable = true)\n",
      " |-- 1990: string (nullable = true)\n",
      " |-- 1991: string (nullable = true)\n",
      " |-- 1992: string (nullable = true)\n",
      " |-- 1993: string (nullable = true)\n",
      " |-- 1994: string (nullable = true)\n",
      " |-- 1995: string (nullable = true)\n",
      " |-- 1996: string (nullable = true)\n",
      " |-- 1997: string (nullable = true)\n",
      " |-- 1998: string (nullable = true)\n",
      " |-- 1999: string (nullable = true)\n",
      " |-- 2000: string (nullable = true)\n",
      " |-- 2001: string (nullable = true)\n",
      " |-- 2002: string (nullable = true)\n",
      " |-- 2003: string (nullable = true)\n",
      " |-- 2004: string (nullable = true)\n",
      " |-- 2005: string (nullable = true)\n",
      " |-- 2006: string (nullable = true)\n",
      " |-- 2007: string (nullable = true)\n",
      " |-- 2008: string (nullable = true)\n",
      " |-- 2009: string (nullable = true)\n",
      " |-- 2010: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 21:04:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/03/12 21:04:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n",
      " Schema: _c0, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(_c0='North America', 1980='320.27638', 1981='324.44694', 1982='328.62014', 1983='332.72487', 1984='336.72143', 1985='340.74811', 1986='344.89548', 1987='349.07829', 1988='353.2939', 1989='357.68457', 1990='362.4468', 1991='367.70684', 1992='373.29069', 1993='378.74233', 1994='383.9166', 1995='388.97216', 1996='393.9428', 1997='398.97205', 1998='403.85585', 1999='408.60296', 2000='413.3245', 2001='417.83236', 2002='422.05268', 2003='426.06238', 2004='430.26938', 2005='434.47232', 2006='438.82964', 2007='443.3473', 2008='447.67394', 2009='451.83698', 2010='456.59331')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 21:04:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n",
      " Schema: _c0, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+-------------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+--------+---------+---------+---------+--------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|          _c0|     1980|     1981|     1982|     1983|     1984|     1985|     1986|     1987|    1988|     1989|    1990|     1991|     1992|     1993|    1994|     1995|    1996|     1997|     1998|     1999|    2000|     2001|     2002|     2003|     2004|     2005|     2006|     2007|     2008|     2009|     2010|\n",
      "+-------------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+--------+---------+---------+---------+--------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|North America|320.27638|324.44694|328.62014|332.72487|336.72143|340.74811|344.89548|349.07829|353.2939|357.68457|362.4468|367.70684|373.29069|378.74233|383.9166|388.97216|393.9428|398.97205|403.85585|408.60296|413.3245|417.83236|422.05268|426.06238|430.26938|434.47232|438.82964| 443.3473|447.67394|451.83698|456.59331|\n",
      "|      Bermuda|  0.05473|  0.05491|  0.05517|  0.05551|  0.05585|  0.05618|  0.05651|  0.05683| 0.05717|  0.05749| 0.05778|   0.0581|   0.0587|  0.05924| 0.05975|  0.06029| 0.06087|  0.06145|  0.06198|  0.06251| 0.06306|  0.06361|  0.06418|  0.06476|  0.06534|  0.06591|  0.06644|  0.06692|  0.06739|  0.06784|  0.06827|\n",
      "|       Canada|  24.5933|     24.9|  25.2019|  25.4563|  25.7018|  25.9416|  26.2038|  26.5497| 26.8948|  27.3793| 27.7906|  28.1179| 28.54489| 28.95334|29.33081| 29.69053|30.02632|  30.3056| 30.55166| 30.82026|31.09956| 31.37674| 31.64096| 31.88931| 32.13476| 32.38638| 32.65668| 32.93596|  33.2127| 33.48721| 33.75974|\n",
      "|    Greenland|  0.05021|  0.05103|  0.05166|  0.05211|  0.05263|  0.05315|  0.05364|   0.0541| 0.05485|  0.05541| 0.05563|  0.05554|  0.05549|  0.05564| 0.05592|  0.05619| 0.05634|  0.05651|  0.05661|   0.0567| 0.05689|  0.05713|  0.05736|  0.05754|   0.0577|  0.05778|  0.05764|  0.05753|  0.05756|   0.0576|  0.05764|\n",
      "|       Mexico| 68.34748| 69.96926|  71.6409| 73.36288| 75.08014| 76.76723| 78.44243| 80.12249|81.78182| 83.36684|84.91365| 86.48803| 88.11103| 89.74914| 91.3379| 92.88035|94.39858| 95.89515| 97.32506| 98.61691|99.92662|101.24696|102.47993|103.71806|104.95959| 106.2029|107.44953|108.70089| 109.9554|111.21179|112.46886|\n",
      "+-------------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+--------+---------+---------+---------+--------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "For region, compute the percentage change in population, year over year. Note the year 1980 will not have a preceding year. For each year, display the region with the top population decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 21:04:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1980, 1981\n",
      " Schema: _c0, 1980, 1981\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+-------+--------+---------+\n",
      "|         _c0|   1980|    1981|1980-1981|\n",
      "+------------+-------+--------+---------+\n",
      "| Afghanistan|15.0436|13.67368|    -9.11|\n",
      "|Cook Islands|0.01801| 0.01765|     -2.0|\n",
      "| El Salvador|4.57041| 4.51972|    -1.11|\n",
      "|    Dominica|0.07389| 0.07352|     -0.5|\n",
      "|    Suriname|0.35408| 0.35251|    -0.44|\n",
      "+------------+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1980, 1981\n",
      " Schema: _c0, 1980, 1981\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1981, 1982\n",
      " Schema: _c0, 1981, 1982\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    1981|    1982|1981-1982|\n",
      "+------------+--------+--------+---------+\n",
      "| Afghanistan|13.67368|12.57743|    -8.02|\n",
      "|   Gibraltar| 0.02927| 0.02885|    -1.43|\n",
      "|Cook Islands| 0.01765| 0.01744|    -1.19|\n",
      "|  Montserrat| 0.01179| 0.01166|     -1.1|\n",
      "|       Malta| 0.36365| 0.36022|    -0.94|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1981, 1982\n",
      " Schema: _c0, 1981, 1982\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1982, 1983\n",
      " Schema: _c0, 1982, 1983\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+-------------------+--------+--------+---------+\n",
      "|                _c0|    1982|    1983|1982-1983|\n",
      "+-------------------+--------+--------+---------+\n",
      "|Antigua and Barbuda| 0.06801| 0.06562|    -3.51|\n",
      "|          Gibraltar| 0.02885| 0.02835|    -1.73|\n",
      "|              Malta| 0.36022| 0.35577|    -1.24|\n",
      "|        Afghanistan|12.57743|12.43058|    -1.17|\n",
      "|         Montserrat| 0.01166| 0.01156|    -0.86|\n",
      "+-------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1982, 1983\n",
      " Schema: _c0, 1982, 1983\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1983, 1984\n",
      " Schema: _c0, 1983, 1984\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+-------------------+-------+-------+---------+\n",
      "|                _c0|   1983|   1984|1983-1984|\n",
      "+-------------------+-------+-------+---------+\n",
      "|Antigua and Barbuda|0.06562|0.06447|    -1.75|\n",
      "|              Malta|0.35577|0.35138|    -1.23|\n",
      "|         Montserrat|0.01156|0.01144|    -1.04|\n",
      "|          Gibraltar|0.02835|0.02823|    -0.42|\n",
      "|      Germany, West|  61.38|  61.13|    -0.41|\n",
      "+-------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1983, 1984\n",
      " Schema: _c0, 1983, 1984\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1984, 1985\n",
      " Schema: _c0, 1984, 1985\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   1984|   1985|1984-1985|\n",
      "+--------------------+-------+-------+---------+\n",
      "|        Cook Islands|0.01774|0.01749|    -1.41|\n",
      "|               Malta|0.35138|0.34704|    -1.24|\n",
      "|            Dominica|0.07399|0.07311|    -1.19|\n",
      "|          Montserrat|0.01144|0.01132|    -1.05|\n",
      "|Saint Kitts and N...|0.04309|0.04293|    -0.37|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1984, 1985\n",
      " Schema: _c0, 1984, 1985\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1985, 1986\n",
      " Schema: _c0, 1985, 1986\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    1985|    1986|1985-1986|\n",
      "+--------------------+--------+--------+---------+\n",
      "|Netherlands Antilles| 0.24443| 0.18433|   -24.59|\n",
      "|            Dominica| 0.07311| 0.07238|     -1.0|\n",
      "|          Montserrat| 0.01132| 0.01121|    -0.97|\n",
      "|Saint Kitts and N...| 0.04293| 0.04273|    -0.47|\n",
      "|             Hungary|10.64871|10.63056|    -0.17|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1985, 1986\n",
      " Schema: _c0, 1985, 1986\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1986, 1987\n",
      " Schema: _c0, 1986, 1987\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    1986|    1987|1986-1987|\n",
      "+------------+--------+--------+---------+\n",
      "|Saint Helena| 0.00831| 0.00654|    -21.3|\n",
      "|  Mozambique|13.14302|12.89485|    -1.89|\n",
      "|  Montserrat| 0.01121| 0.01109|    -1.07|\n",
      "|       Aruba|  0.0598| 0.05918|    -1.04|\n",
      "|    Dominica| 0.07238| 0.07182|    -0.77|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1986, 1987\n",
      " Schema: _c0, 1986, 1987\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1987, 1988\n",
      " Schema: _c0, 1987, 1988\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    1987|    1988|1987-1988|\n",
      "+--------------------+--------+--------+---------+\n",
      "|          Mozambique|12.89485|12.52301|    -2.88|\n",
      "|             Hungary|10.61274| 10.4425|     -1.6|\n",
      "|          Montserrat| 0.01109| 0.01097|    -1.08|\n",
      "|               Tonga|   0.094| 0.09332|    -0.72|\n",
      "|Saint Kitts and N...| 0.04248| 0.04219|    -0.68|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1987, 1988\n",
      " Schema: _c0, 1987, 1988\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1988, 1989\n",
      " Schema: _c0, 1988, 1989\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   1988|   1989|1988-1989|\n",
      "+--------------------+-------+-------+---------+\n",
      "|             Somalia|6.91829|6.76633|     -2.2|\n",
      "|            Dominica|0.07134|0.07051|    -1.16|\n",
      "|          Montserrat|0.01097|0.01085|    -1.09|\n",
      "|Saint Kitts and N...|0.04219|0.04192|    -0.64|\n",
      "|               Tonga|0.09332|0.09278|    -0.58|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1988, 1989\n",
      " Schema: _c0, 1988, 1989\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1989, 1990\n",
      " Schema: _c0, 1989, 1990\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+-------------+--------+--------+---------+\n",
      "|          _c0|    1989|    1990|1989-1990|\n",
      "+-------------+--------+--------+---------+\n",
      "|      Liberia| 2.45297| 2.13859|   -12.82|\n",
      "|    Gibraltar| 0.03042| 0.02911|    -4.31|\n",
      "|Germany, East|16.65491|16.15039|    -3.03|\n",
      "| South Africa|39.04797|38.47627|    -1.46|\n",
      "|   Montserrat| 0.01085| 0.01073|    -1.11|\n",
      "+-------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1989, 1990\n",
      " Schema: _c0, 1989, 1990\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1990, 1991\n",
      " Schema: _c0, 1990, 1991\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+---------+--------+--------+---------+\n",
      "|      _c0|    1990|    1991|1990-1991|\n",
      "+---------+--------+--------+---------+\n",
      "|   Kuwait| 2.14206| 0.95422|   -55.45|\n",
      "|  Liberia| 2.13859| 1.81471|   -15.14|\n",
      "|     Iraq|18.13996|17.47737|    -3.65|\n",
      "|Gibraltar| 0.02911|  0.0281|    -3.47|\n",
      "|  Somalia| 6.69204| 6.46448|     -3.4|\n",
      "+---------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1990, 1991\n",
      " Schema: _c0, 1990, 1991\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1991, 1992\n",
      " Schema: _c0, 1991, 1992\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+-------+-------+---------+\n",
      "|         _c0|   1991|   1992|1991-1992|\n",
      "+------------+-------+-------+---------+\n",
      "|     Somalia|6.46448|6.11621|    -5.39|\n",
      "|      Bhutan|0.62504|0.60166|    -3.74|\n",
      "|     Albania|3.18105|3.07201|    -3.43|\n",
      "|Sierra Leone| 4.3349|4.24628|    -2.04|\n",
      "|    Bulgaria|8.77237|8.65851|     -1.3|\n",
      "+------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1991, 1992\n",
      " Schema: _c0, 1991, 1992\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1992, 1993\n",
      " Schema: _c0, 1992, 1993\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   1992|   1993|1992-1993|\n",
      "+--------------------+-------+-------+---------+\n",
      "|Bosnia and Herzeg...|4.25601|3.95502|    -7.07|\n",
      "|             Armenia|3.37833|3.23157|    -4.34|\n",
      "|              Bhutan|0.60166|0.57669|    -4.15|\n",
      "|       Faroe Islands|0.04778|0.04609|    -3.54|\n",
      "|        Sierra Leone|4.24628|4.09967|    -3.45|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1992, 1993\n",
      " Schema: _c0, 1992, 1993\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1993, 1994\n",
      " Schema: _c0, 1993, 1994\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    1993|    1994|1993-1994|\n",
      "+--------------------+--------+--------+---------+\n",
      "|              Rwanda| 7.59668| 6.50553|   -14.36|\n",
      "|Bosnia and Herzeg...| 3.95502| 3.78498|     -4.3|\n",
      "|U.S. Pacific Islands| 0.23438| 0.22598|    -3.58|\n",
      "|            Ethiopia|56.03139|54.03425|    -3.56|\n",
      "|       Faroe Islands| 0.04609|  0.0445|    -3.45|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1993, 1994\n",
      " Schema: _c0, 1993, 1994\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1994, 1995\n",
      " Schema: _c0, 1994, 1995\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   1994|   1995|1994-1995|\n",
      "+--------------------+-------+-------+---------+\n",
      "|              Rwanda|6.50553|5.47298|   -15.87|\n",
      "|        Sierra Leone|3.97796|3.88144|    -2.43|\n",
      "|       Faroe Islands| 0.0445|0.04354|    -2.16|\n",
      "|             Georgia|5.12081|5.01295|    -2.11|\n",
      "|Bosnia and Herzeg...|3.78498|3.70896|    -2.01|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1994, 1995\n",
      " Schema: _c0, 1994, 1995\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1995, 1996\n",
      " Schema: _c0, 1995, 1996\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   1995|   1996|1995-1996|\n",
      "+--------------------+-------+-------+---------+\n",
      "|          Montserrat|0.01027|0.00795|   -22.59|\n",
      "|Bosnia and Herzeg...|3.70896| 3.6085|    -2.71|\n",
      "|        Sierra Leone|3.88144| 3.8105|    -1.83|\n",
      "|             Georgia|5.01295|4.93457|    -1.56|\n",
      "|             Estonia|1.44651|1.42783|    -1.29|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1995, 1996\n",
      " Schema: _c0, 1995, 1996\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1996, 1997\n",
      " Schema: _c0, 1996, 1997\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    1996|    1997|1996-1997|\n",
      "+------------+--------+--------+---------+\n",
      "|  Montserrat| 0.00795| 0.00595|   -25.16|\n",
      "|Cook Islands| 0.01818| 0.01787|    -1.71|\n",
      "|  Kazakhstan|15.69609|15.48452|    -1.35|\n",
      "|Sierra Leone|  3.8105| 3.76521|    -1.19|\n",
      "|    Bulgaria| 8.16103| 8.06606|    -1.16|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1996, 1997\n",
      " Schema: _c0, 1996, 1997\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1997, 1998\n",
      " Schema: _c0, 1997, 1998\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    1997|    1998|1997-1998|\n",
      "+--------------------+--------+--------+---------+\n",
      "|          Montserrat| 0.00595| 0.00338|   -43.19|\n",
      "|        Cook Islands| 0.01787| 0.01738|    -2.74|\n",
      "|          Kazakhstan|15.48452| 15.2471|    -1.53|\n",
      "|        Korea, North|21.47045|21.20487|    -1.24|\n",
      "|Former Serbia and...|10.47286|10.34279|    -1.24|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1997, 1998\n",
      " Schema: _c0, 1997, 1998\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1998, 1999\n",
      " Schema: _c0, 1998, 1999\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    1998|    1999|1998-1999|\n",
      "+--------------------+--------+--------+---------+\n",
      "|        Cook Islands| 0.01738| 0.01686|    -2.99|\n",
      "|Former Serbia and...|10.34279| 10.1599|    -1.77|\n",
      "|          Kazakhstan| 15.2471|15.08462|    -1.07|\n",
      "|            Bulgaria| 7.97177| 7.89323|    -0.99|\n",
      "|             Ukraine| 49.9372|49.48506|    -0.91|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1998, 1999\n",
      " Schema: _c0, 1998, 1999\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1999, 2000\n",
      " Schema: _c0, 1999, 2000\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    1999|    2000|1999-2000|\n",
      "+--------------------+--------+--------+---------+\n",
      "|        Cook Islands| 0.01686| 0.01631|    -3.26|\n",
      "|Former Serbia and...| 10.1599|10.03677|    -1.21|\n",
      "|             Ukraine|49.48506|49.00522|    -0.97|\n",
      "|            Bulgaria| 7.89323|  7.8185|    -0.95|\n",
      "|             Albania| 3.18733| 3.15835|    -0.91|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1999, 2000\n",
      " Schema: _c0, 1999, 2000\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:04:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2000, 2001\n",
      " Schema: _c0, 2000, 2001\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    2000|    2001|2000-2001|\n",
      "+------------+--------+--------+---------+\n",
      "|Cook Islands| 0.01631| 0.01573|    -3.56|\n",
      "|    Bulgaria|  7.8185| 7.73842|    -1.02|\n",
      "|     Ukraine|49.00522|48.50792|    -1.01|\n",
      "|     Albania| 3.15835|   3.128|    -0.96|\n",
      "|      Latvia| 2.37618| 2.35823|    -0.76|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:04:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2000, 2001\n",
      " Schema: _c0, 2000, 2001\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2001, 2002\n",
      " Schema: _c0, 2001, 2002\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    2001|    2002|2001-2002|\n",
      "+------------+--------+--------+---------+\n",
      "|Cook Islands| 0.01573| 0.01515|    -3.69|\n",
      "|    Bulgaria| 7.73842|  7.6618|    -0.99|\n",
      "|     Albania|   3.128| 3.09803|    -0.96|\n",
      "|     Ukraine|48.50792|48.05682|    -0.93|\n",
      "|      Latvia| 2.35823| 2.34021|    -0.76|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2001, 2002\n",
      " Schema: _c0, 2001, 2002\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2002, 2003\n",
      " Schema: _c0, 2002, 2003\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+-------+-------+---------+\n",
      "|         _c0|   2002|   2003|2002-2003|\n",
      "+------------+-------+-------+---------+\n",
      "|  Montserrat|0.00481|0.00449|    -6.65|\n",
      "|Cook Islands|0.01515| 0.0146|    -3.63|\n",
      "|    Djibouti|0.71635|0.69078|    -3.57|\n",
      "|    Bulgaria| 7.6618| 7.5884|    -0.96|\n",
      "|     Albania|3.09803|3.06967|    -0.92|\n",
      "+------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2002, 2003\n",
      " Schema: _c0, 2002, 2003\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2003, 2004\n",
      " Schema: _c0, 2003, 2004\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    2003|    2004|2003-2004|\n",
      "+------------+--------+--------+---------+\n",
      "|    Djibouti| 0.69078| 0.65741|    -4.83|\n",
      "|Cook Islands|  0.0146| 0.01409|    -3.49|\n",
      "|    Bulgaria|  7.5884| 7.51797|    -0.93|\n",
      "|     Albania| 3.06967| 3.04564|    -0.78|\n",
      "|     Ukraine|47.66708|47.30539|    -0.76|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2003, 2004\n",
      " Schema: _c0, 2003, 2004\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2004, 2005\n",
      " Schema: _c0, 2004, 2005\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+--------+--------+---------+\n",
      "|                 _c0|    2004|    2005|2004-2005|\n",
      "+--------------------+--------+--------+---------+\n",
      "|          Montserrat| 0.00496| 0.00453|    -8.67|\n",
      "|        Cook Islands| 0.01409|  0.0136|    -3.48|\n",
      "|U.S. Pacific Islands| 0.26494| 0.25814|    -2.57|\n",
      "|            Bulgaria| 7.51797| 7.45035|     -0.9|\n",
      "|            Zimbabwe|11.73505|11.63947|    -0.81|\n",
      "+--------------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2004, 2005\n",
      " Schema: _c0, 2004, 2005\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2005, 2006\n",
      " Schema: _c0, 2005, 2006\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   2005|   2006|2005-2006|\n",
      "+--------------------+-------+-------+---------+\n",
      "|               Nauru|0.01001|0.00957|     -4.4|\n",
      "|        Cook Islands| 0.0136|0.01313|    -3.46|\n",
      "|U.S. Pacific Islands|0.25814|0.24957|    -3.32|\n",
      "|             Lebanon|3.89239| 3.8511|    -1.06|\n",
      "|            Bulgaria|7.45035|7.38537|    -0.87|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2005, 2006\n",
      " Schema: _c0, 2005, 2006\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2006, 2007\n",
      " Schema: _c0, 2006, 2007\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+------------+--------+--------+---------+\n",
      "|         _c0|    2006|    2007|2006-2007|\n",
      "+------------+--------+--------+---------+\n",
      "|       Nauru| 0.00957| 0.00912|     -4.7|\n",
      "|Cook Islands| 0.01313| 0.01269|    -3.35|\n",
      "|  Montserrat| 0.00463| 0.00451|    -2.59|\n",
      "|  Montenegro| 0.69187| 0.68474|    -1.03|\n",
      "|    Zimbabwe|11.54433|11.44319|    -0.88|\n",
      "+------------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2006, 2007\n",
      " Schema: _c0, 2006, 2007\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2007, 2008\n",
      " Schema: _c0, 2007, 2008\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   2007|   2008|2007-2008|\n",
      "+--------------------+-------+-------+---------+\n",
      "|        Cook Islands|0.01269|0.01227|    -3.31|\n",
      "|          Montenegro|0.68474|0.67818|    -0.96|\n",
      "|U.S. Pacific Islands|0.24888|0.24678|    -0.84|\n",
      "|            Bulgaria|7.32286|7.26268|    -0.82|\n",
      "|Saint Pierre and ...| 0.0061|0.00605|    -0.82|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2007, 2008\n",
      " Schema: _c0, 2007, 2008\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2008, 2009\n",
      " Schema: _c0, 2008, 2009\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   2008|   2009|2008-2009|\n",
      "+--------------------+-------+-------+---------+\n",
      "|        Cook Islands|0.01227|0.01187|    -3.26|\n",
      "|U.S. Pacific Islands|0.24678|0.24424|    -1.03|\n",
      "|          Montenegro|0.67818|0.67218|    -0.88|\n",
      "|Saint Pierre and ...|0.00605|  0.006|    -0.83|\n",
      "|            Bulgaria|7.26268|7.20469|     -0.8|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2008, 2009\n",
      " Schema: _c0, 2008, 2009\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "23/03/12 21:05:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2009, 2010\n",
      " Schema: _c0, 2009, 2010\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n",
      "+--------------------+-------+-------+---------+\n",
      "|                 _c0|   2009|   2010|2009-2010|\n",
      "+--------------------+-------+-------+---------+\n",
      "|        Cook Islands|0.01187|0.01149|     -3.2|\n",
      "|               Haiti|9.77797|9.64892|    -1.32|\n",
      "|Saint Pierre and ...|  0.006|0.00594|     -1.0|\n",
      "|U.S. Pacific Islands|0.24424|0.24221|    -0.83|\n",
      "|          Montenegro|0.67218|0.66673|    -0.81|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/03/12 21:05:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2009, 2010\n",
      " Schema: _c0, 2009, 2010\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/shared/hw2/populationbycountry19802010millions.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "result = []\n",
    "\n",
    "for previous_year, current_year in zip(df.columns[1:], df.columns[2:]):\n",
    "    year_range = previous_year + \"-\" + current_year\n",
    "    df_year_range = df.select(\"_c0\", previous_year, current_year)\n",
    "    df_year_range = df_year_range.withColumn(\n",
    "        year_range, \n",
    "        round(((col(current_year) - col(previous_year)) / col(previous_year) * 100 ), 2)\n",
    "    ).na.drop()\n",
    "    df_year_range.sort(col(year_range)).show(5)\n",
    "    df_top = df_year_range.orderBy(col(year_range)).first()\n",
    "    result.append(df_top[\"_c0\"] + \",\" + str(df_top[year_range]) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980 Afghanistan,-9.11%\n",
      "1981 Afghanistan,-8.02%\n",
      "1982 Antigua and Barbuda,-3.51%\n",
      "1983 Antigua and Barbuda,-1.75%\n",
      "1984 Cook Islands,-1.41%\n",
      "1985 Netherlands Antilles,-24.59%\n",
      "1986 Saint Helena,-21.3%\n",
      "1987 Mozambique,-2.88%\n",
      "1988 Somalia,-2.2%\n",
      "1989 Liberia,-12.82%\n",
      "1990 Kuwait,-55.45%\n",
      "1991 Somalia,-5.39%\n",
      "1992 Bosnia and Herzegovina,-7.07%\n",
      "1993 Rwanda,-14.36%\n",
      "1994 Rwanda,-15.87%\n",
      "1995 Montserrat,-22.59%\n",
      "1996 Montserrat,-25.16%\n",
      "1997 Montserrat,-43.19%\n",
      "1998 Cook Islands,-2.99%\n",
      "1999 Cook Islands,-3.26%\n",
      "2000 Cook Islands,-3.56%\n",
      "2001 Cook Islands,-3.69%\n",
      "2002 Montserrat,-6.65%\n",
      "2003 Djibouti,-4.83%\n",
      "2004 Montserrat,-8.67%\n",
      "2005 Nauru,-4.4%\n",
      "2006 Nauru,-4.7%\n",
      "2007 Cook Islands,-3.31%\n",
      "2008 Cook Islands,-3.26%\n",
      "2009 Cook Islands,-3.2%\n"
     ]
    }
   ],
   "source": [
    "year = 1980\n",
    "for top in result:\n",
    "    print(year, top)\n",
    "    year = year + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: romeo-juliet-pg1777.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = spark.read.text(\"shared/hw2/romeo-juliet-pg1777.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|                    |\n",
      "|This Etext file i...|\n",
      "|cooperation with ...|\n",
      "|Future and Shakes...|\n",
      "|Etexts that are N...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Do word count in pyspark. Ignore punctuation, and normalize to lower case. Accept only the characters in this set: `[0-9a-zA-Z]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Word: string (nullable = true)\n",
      " |-- Count: long (nullable = true)\n",
      "\n",
      "+---------+-----+\n",
      "|     Word|Count|\n",
      "+---------+-----+\n",
      "|     this|  258|\n",
      "|    etext|   29|\n",
      "|     file|    3|\n",
      "|       is|  383|\n",
      "|presented|    1|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^0-9a-zA-Z]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "lines = txt.rdd.map(lambda r: r[0])\n",
    "\n",
    "word_counts = lines.flatMap(lambda line: line.split(\" \")) \\\n",
    "                  .map(lambda word: (normalize_text(word), 1)) \\\n",
    "                  .filter(lambda pair: len(pair[0]) > 0) \\\n",
    "                  .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "df_wordcount = spark.createDataFrame(word_counts, ['Word', 'Count'])\n",
    "\n",
    "df_wordcount.printSchema()\n",
    "df_wordcount.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets:\n",
    "#  Restaurants_in_Durham_County_NC.csv\n",
    "#  durham-nc-foreclosure-2006-2016.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7\n",
    "\n",
    "For each restaurant (`Restaurants_in_Durham_County_NC.csv`) with `status`=`ACTIVE` and `rpt_area_desc`=`Food Service`, show the number of foreclosures (`durham-nc-foreclosure-2006-2016`) within a radius of 1 mile of the restaurant’s coordinates.\n",
    "\n",
    "Note: You can use the Haversine distance. https://pypi.org/project/haversine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Premise_Name: string (nullable = true)\n",
      " |-- Premise_Address1: string (nullable = true)\n",
      " |-- Premise_Address2: string (nullable = true)\n",
      " |-- Premise_City: string (nullable = true)\n",
      " |-- Premise_State: string (nullable = true)\n",
      " |-- Premise_Zip: string (nullable = true)\n",
      " |-- Premise_Phone: string (nullable = true)\n",
      " |-- Hours_Of_Operation: string (nullable = true)\n",
      " |-- Opening_Date: string (nullable = true)\n",
      " |-- Closing_Date: string (nullable = true)\n",
      " |-- Seats: string (nullable = true)\n",
      " |-- Water: string (nullable = true)\n",
      " |-- Sewage: string (nullable = true)\n",
      " |-- Insp_Freq: string (nullable = true)\n",
      " |-- Est_Group_Desc: string (nullable = true)\n",
      " |-- Risk: integer (nullable = true)\n",
      " |-- Smoking_Allowed: string (nullable = true)\n",
      " |-- Type_Description: string (nullable = true)\n",
      " |-- Rpt_Area_Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Transitional_Type_Desc: string (nullable = true)\n",
      " |-- geolocation: string (nullable = true)\n",
      "\n",
      "+------+--------------------+-------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "|    ID|        Premise_Name|   Premise_Address1|Premise_Address2|Premise_City|Premise_State|Premise_Zip| Premise_Phone|Hours_Of_Operation|Opening_Date|Closing_Date|Seats|               Water|              Sewage|Insp_Freq|Est_Group_Desc|Risk|Smoking_Allowed|    Type_Description|   Rpt_Area_Desc|Status|Transitional_Type_Desc|         geolocation|\n",
      "+------+--------------------+-------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "| 60782|FRANCIS STREET WO...|2404 FRANCIS STREET|            null|      DURHAM|           NC|      27707|(919) 425-5474|              null|  2008-06-02|        null|   10|5 - Municipal/Com...|3 - Municipal/Com...|        1|          null|   0|            N/A|43 - Residential ...|Residential Care|ACTIVE|                   N/A|35.975057, -78.93...|\n",
      "| 59238|FITNESS CONNECTIO...|4700-A EMPEROR BLVD|            null|      DURHAM|           NC|      27703|          null|              null|  1996-03-01|        null|    0|5 - Municipal/Com...|3 - Municipal/Com...|        2|          null|   0|            N/A| 55 - Year-Round Spa|  Swimming Pools|ACTIVE|                   N/A|35.8767831, -78.8...|\n",
      "|178996|MORTAR AND GRIND ...|1101 CHAPEL HILL ST|            null|      DURHAM|           NC|      27701|(919) 593-2107|              null|  2016-08-09|        null| null|5 - Municipal/Com...|3 - Municipal/Com...|        2|          null|   2|            N/A|     2 - Food Stands|    Food Service|ACTIVE|                  FOOD|35.9965963, -78.9...|\n",
      "| 58745|DURHAM SCHOOL OF ...|      401 N DUKE ST|            null|      DURHAM|           NC|      27701|(919) 560-2217|              null|  1995-05-02|        null|    0|5 - Municipal/Com...|3 - Municipal/Com...|        1|          null|   0|            N/A|44 - School Building|School Buildings|ACTIVE|                   N/A|36.002815, -78.90...|\n",
      "|116820|   INTER KOREA HOUSE|      4731 NC HWY55|            null|      DURHAM|           NC|      27713|(919) 572-9132|              null|  2013-04-09|        null|   60|5 - Municipal/Com...|3 - Municipal/Com...|        4|          null|   4|            N/A|      1 - Restaurant|    Food Service|ACTIVE|                  FOOD|35.9009097, -78.8...|\n",
      "+------+--------------------+-------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------+----+---------------+--------------------+----------------+------+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restaurants = spark.read\\\n",
    "    .option(\"delimiter\", \";\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .option(\"header\", True)\\\n",
    "    .csv(\"shared/hw2/Restaurants_in_Durham_County_NC.csv\")\\\n",
    "    .repartition(10)\n",
    "\n",
    "restaurants.printSchema()\n",
    "restaurants.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datasetid: string (nullable = true)\n",
      " |-- fields: struct (nullable = true)\n",
      " |    |-- address: string (nullable = true)\n",
      " |    |-- geocode: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- parcel_number: string (nullable = true)\n",
      " |    |-- year: string (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- record_timestamp: string (nullable = true)\n",
      " |-- recordid: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           datasetid|              fields|            geometry|    record_timestamp|            recordid|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|foreclosure-2006-...|{6117 KELVIN DR, ...|{[-78.956498, 36....|2017-03-06T12:41:...|a9bd7d8b97effeba4...|\n",
      "|foreclosure-2006-...|{613 HARNETT ST, ...|{[-78.8781489, 35...|2017-03-06T12:41:...|6abbbfe5593395f7c...|\n",
      "|foreclosure-2006-...|{1009 MIDLAND TER...|{[-78.8612179, 36...|2017-03-06T12:41:...|bce5a641e8c280060...|\n",
      "|foreclosure-2006-...|{129 CHESTNUT ST,...|{[-78.9054859, 35...|2017-03-06T12:41:...|c5fe0498f904f15c5...|\n",
      "|foreclosure-2006-...|{4816 STANLEY RD,...|{[-78.872153, 36....|2017-03-06T12:41:...|31a5c9fec178cf2c8...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "foreclosures = spark.read\\\n",
    "    .json(\"shared/hw2/durham-nc-foreclosure-2006-2016.json\")\\\n",
    "    .repartition(10)\n",
    "\n",
    "foreclosures.printSchema()\n",
    "foreclosures.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Premise_Name: string (nullable = true)\n",
      " |-- Premise_Address1: string (nullable = true)\n",
      " |-- Premise_Address2: string (nullable = true)\n",
      " |-- Premise_City: string (nullable = true)\n",
      " |-- Premise_State: string (nullable = true)\n",
      " |-- Premise_Zip: string (nullable = true)\n",
      " |-- Premise_Phone: string (nullable = true)\n",
      " |-- Hours_Of_Operation: string (nullable = true)\n",
      " |-- Opening_Date: string (nullable = true)\n",
      " |-- Closing_Date: string (nullable = true)\n",
      " |-- Seats: string (nullable = true)\n",
      " |-- Water: string (nullable = true)\n",
      " |-- Sewage: string (nullable = true)\n",
      " |-- Insp_Freq: string (nullable = true)\n",
      " |-- Est_Group_Desc: string (nullable = true)\n",
      " |-- Risk: integer (nullable = true)\n",
      " |-- Smoking_Allowed: string (nullable = true)\n",
      " |-- Type_Description: string (nullable = true)\n",
      " |-- Rpt_Area_Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Transitional_Type_Desc: string (nullable = true)\n",
      " |-- geolocation: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      "\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+\n",
      "|   ID|Premise_Name|    Premise_Address1|Premise_Address2|Premise_City|Premise_State|Premise_Zip| Premise_Phone|Hours_Of_Operation|Opening_Date|Closing_Date|Seats|               Water|              Sewage|Insp_Freq|      Est_Group_Desc|Risk|Smoking_Allowed|Type_Description|Rpt_Area_Desc|Status|Transitional_Type_Desc|         geolocation|  Latitude|   Longitude|       long|       lat|\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.9054859|35.9860296|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.8999963|35.9828632|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.905474| 35.982741|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.8994869| 35.955334|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.877483| 35.990061|\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "active = restaurants\\\n",
    "    .filter((col(\"status\") == \"ACTIVE\") & (col(\"Rpt_Area_Desc\") == \"Food Service\"))\\\n",
    "    .withColumn(\"Latitude\", split(col(\"geolocation\"), \",\").getItem(0))\\\n",
    "    .withColumn(\"Longitude\", split(col(\"geolocation\"), \",\").getItem(1))\n",
    "\n",
    "coordinates = foreclosures.select(\n",
    "    foreclosures.geometry.coordinates[0].alias(\"long\"),\n",
    "    foreclosures.geometry.coordinates.getItem(1).alias(\"lat\")\n",
    ")\n",
    "\n",
    "result = active.crossJoin(coordinates)\n",
    "\n",
    "result.printSchema()\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine, Unit\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf(returnType=FloatType())\n",
    "def haversine_dist(lat_x, long_x, lat_y, long_y):\n",
    "    if long_x== None or lat_x == None or long_y == None or lat_y == None:\n",
    "        return 2000.0\n",
    "    return haversine((lat_x, long_x), (float(lat_y), float(long_y)), unit=Unit.MILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Premise_Name: string (nullable = true)\n",
      " |-- Premise_Address1: string (nullable = true)\n",
      " |-- Premise_Address2: string (nullable = true)\n",
      " |-- Premise_City: string (nullable = true)\n",
      " |-- Premise_State: string (nullable = true)\n",
      " |-- Premise_Zip: string (nullable = true)\n",
      " |-- Premise_Phone: string (nullable = true)\n",
      " |-- Hours_Of_Operation: string (nullable = true)\n",
      " |-- Opening_Date: string (nullable = true)\n",
      " |-- Closing_Date: string (nullable = true)\n",
      " |-- Seats: string (nullable = true)\n",
      " |-- Water: string (nullable = true)\n",
      " |-- Sewage: string (nullable = true)\n",
      " |-- Insp_Freq: string (nullable = true)\n",
      " |-- Est_Group_Desc: string (nullable = true)\n",
      " |-- Risk: integer (nullable = true)\n",
      " |-- Smoking_Allowed: string (nullable = true)\n",
      " |-- Type_Description: string (nullable = true)\n",
      " |-- Rpt_Area_Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Transitional_Type_Desc: string (nullable = true)\n",
      " |-- geolocation: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- distance: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+---------+\n",
      "|   ID|Premise_Name|    Premise_Address1|Premise_Address2|Premise_City|Premise_State|Premise_Zip| Premise_Phone|Hours_Of_Operation|Opening_Date|Closing_Date|Seats|               Water|              Sewage|Insp_Freq|      Est_Group_Desc|Risk|Smoking_Allowed|Type_Description|Rpt_Area_Desc|Status|Transitional_Type_Desc|         geolocation|  Latitude|   Longitude|       long|       lat| distance|\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+---------+\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.9054859|35.9860296|4.9976087|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.8999963|35.9828632|5.2178335|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.905474| 35.982741|5.2247424|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.8994869| 35.955334|7.1198726|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.877483| 35.990061|4.9315085|\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = result.withColumn(\n",
    "    \"distance\", \n",
    "    haversine_dist(\n",
    "        col(\"lat\"),\n",
    "        col(\"long\"),\n",
    "        col(\"Latitude\"),\n",
    "        col(\"Longitude\")\n",
    "    ).alias(\"distance\")\n",
    ")\n",
    "\n",
    "result.printSchema()\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Premise_Name: string (nullable = true)\n",
      " |-- Premise_Address1: string (nullable = true)\n",
      " |-- Premise_Address2: string (nullable = true)\n",
      " |-- Premise_City: string (nullable = true)\n",
      " |-- Premise_State: string (nullable = true)\n",
      " |-- Premise_Zip: string (nullable = true)\n",
      " |-- Premise_Phone: string (nullable = true)\n",
      " |-- Hours_Of_Operation: string (nullable = true)\n",
      " |-- Opening_Date: string (nullable = true)\n",
      " |-- Closing_Date: string (nullable = true)\n",
      " |-- Seats: string (nullable = true)\n",
      " |-- Water: string (nullable = true)\n",
      " |-- Sewage: string (nullable = true)\n",
      " |-- Insp_Freq: string (nullable = true)\n",
      " |-- Est_Group_Desc: string (nullable = true)\n",
      " |-- Risk: integer (nullable = true)\n",
      " |-- Smoking_Allowed: string (nullable = true)\n",
      " |-- Type_Description: string (nullable = true)\n",
      " |-- Rpt_Area_Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Transitional_Type_Desc: string (nullable = true)\n",
      " |-- geolocation: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- distance: float (nullable = true)\n",
      "\n",
      "23/03/12 21:05:10 WARN ExtractPythonUDFFromJoinCondition: The join condition:(haversine_dist(lat#2302, long#2301, Latitude#2250, Longitude#2275)#2466 <= 1.0) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 154:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+----------+\n",
      "|   ID|Premise_Name|    Premise_Address1|Premise_Address2|Premise_City|Premise_State|Premise_Zip| Premise_Phone|Hours_Of_Operation|Opening_Date|Closing_Date|Seats|               Water|              Sewage|Insp_Freq|      Est_Group_Desc|Risk|Smoking_Allowed|Type_Description|Rpt_Area_Desc|Status|Transitional_Type_Desc|         geolocation|  Latitude|   Longitude|       long|       lat|  distance|\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+----------+\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.898467| 36.053406|0.43133345|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.897111| 36.064923|0.56816316|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023| -78.899759| 36.046058|0.86994225|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.9041444|36.0628206|0.31421095|\n",
      "|55475|BOJANGLES #6|4525 N. ROXBORO ROAD|            null|      DURHAM|           NC|      27704|(919) 471-0581|              null|  1990-07-01|        null|   80|5 - Municipal/Com...|3 - Municipal/Com...|        3|Fast Food Restaurant|   3|             NO|  1 - Restaurant| Food Service|ACTIVE|                  FOOD|36.0583372, -78.9...|36.0583372| -78.9032023|-78.9032469| 36.069163| 0.7479957|\n",
      "+-----+------------+--------------------+----------------+------------+-------------+-----------+--------------+------------------+------------+------------+-----+--------------------+--------------------+---------+--------------------+----+---------------+----------------+-------------+------+----------------------+--------------------+----------+------------+-----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = result.filter(col(\"distance\") <= 1.0)\n",
    "\n",
    "result.printSchema()\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 21:05:15 WARN ExtractPythonUDFFromJoinCondition: The join condition:(haversine_dist(lat#2302, long#2301, Latitude#2250, Longitude#2275)#2466 <= 1.0) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 160:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|        Premise_name|  distance|\n",
      "+--------------------+----------+\n",
      "|DELECTABLE-DELECT...| 0.9322919|\n",
      "|       THE BAGEL BAR|0.76186764|\n",
      "|DANISH MEXICAN RE...|0.37278858|\n",
      "|EL RODEO OF DURHA...| 0.9912659|\n",
      "|             LITTLER|0.70784277|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.select('Premise_name', 'distance').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Premise_name: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n",
      "23/03/12 21:05:18 WARN ExtractPythonUDFFromJoinCondition: The join condition:(haversine_dist(lat#2302, long#2301, Latitude#2250, Longitude#2275)#2466 <= 1.0) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 166:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        Premise_name|count|\n",
      "+--------------------+-----+\n",
      "|     DPAC  3RD FLOOR|  267|\n",
      "|W G PEARSON SCHOO...|  199|\n",
      "|      EL DORADO'S #6|    5|\n",
      "|            GRILL 46|   17|\n",
      "|  COMPARE FOODS DELI|   65|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = result.groupBy('Premise_name').count()\n",
    "\n",
    "result.printSchema()\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 21:05:32 WARN ExtractPythonUDFFromJoinCondition: The join condition:(haversine_dist(lat#2302, long#2301, Latitude#2250, Longitude#2275)#2466 <= 1.0) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        Premise_name|count|\n",
      "+--------------------+-----+\n",
      "|              SUBWAY|  882|\n",
      "|TOP'S CHINA RESTA...|  638|\n",
      "|    TATER BREAD CAFE|  516|\n",
      "|LOS PRIMOS SUPERM...|  515|\n",
      "|     THE COTTON ROOM|  486|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.orderBy(desc(\"count\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
